{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pytorch Example Explanation\n",
    "\n",
    "First thing to note is that it is generally very bad practice to run pytorch in jupyter notebook. I simply created this to make it easier to understand what is going on in the code.\n",
    "\n",
    "For this example, I will demonstrate how to design a simple network that will attempt to refocus an image.\n",
    "\n",
    "## Part 1: Import packages and Load the data\n",
    "\n",
    "Hopefully, you have already installed pytorch on your machine. If not, go to pytorch.org to install it. If you are on Windows, install Anaconda and run *conda install -c peterjc123 pytorch* .\n",
    "\n",
    "From there, you should be able to import all the pytorch packages you need."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.autograd import Variable\n",
    "import torch.utils.data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And of course, good ol' Numpy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From here, we will need to load in our data. The easiest way is to prepare that data using Numpy. If you need help loading images into Numpy, see the imageLoader.py file.\n",
    "\n",
    "Once you have all your data in a .npy file, we can bring it in."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "filename_original = \"original.npy\"\n",
    "filename_refocused = \"refocused.npy\"\n",
    "\n",
    "original_data = np.load(filename_original).astype(np.float32)\n",
    "refocused_data = np.load(filename_refocused).astype(np.float32)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There a specific way that pytorch likes to see the data. Specifically, it will be a 4d tensor where the dimensions are as follows:\n",
    "\n",
    "**[image number, color channel, pixel row, pixel column]**\n",
    "\n",
    "Thus, a data set with 1400 images that are 540 x 375 and 3 color channels would have a total size of [1400,3,375,540]. In Numpy, the convention is [image number, pixel row, pixel column, color channel], so we need to transpose the data so the dimenisons line up properly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Reshape data for pytorch\n",
    "original_data = np.transpose(original_data, (0,3,1,2))\n",
    "refocused_data = np.transpose(refocused_data, (0,3,1,2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we need to split our data into a training set and a testing set. Convention is usually an 80/20 split. Since I have provided 100 images, that means we should split at 80."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Train/Test split \n",
    "split = 80\n",
    "train_orig = original_data[:split]\n",
    "train_refc = refocused_data[:split]\n",
    "test_orig = original_data[split:]\n",
    "test_refc = refocused_data[split:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 2: Designing the Network\n",
    "\n",
    "Now it is time to design the layers of our neural network. The simplest version of a neural network is designed by alternating layers of linear weights and non linear functions.\n",
    "\n",
    "Examples of linear weight layers:\n",
    "- Convolution: Considers nearby pixels and combines in a linear fashion.\n",
    "- Fully Connected: Every pixel effects every other pixel (equivalent to a matrix multiply).\n",
    "\n",
    "Examples of nonlinear functions:\n",
    "- ReLU: Most common, super fast, eliminates negative weights.\n",
    "- Sigmoid: Scales input between 0 and 1.\n",
    "\n",
    "It is really difficult to explain why we want our layer design (topology) to be the way it is, but suffice it to say that a network that only contains convolutions (CNN) is all that we need in this case. For more details on how each layer is defined, see the pytorch specs (just Google it)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model = torch.nn.Sequential(\n",
    "    torch.nn.Conv2d(3, 64, 3, stride=1, padding=1),\n",
    "    torch.nn.ReLU(),\n",
    "    torch.nn.Conv2d(64, 64, 3, stride=1, padding=1),\n",
    "    torch.nn.ReLU(),\n",
    "    torch.nn.Conv2d(64, 64, 3, stride=1, padding=1),\n",
    "    torch.nn.ReLU(),\n",
    "    torch.nn.Conv2d(64, 64, 3, stride=1, padding=1),\n",
    "    torch.nn.ReLU(),\n",
    "    torch.nn.Conv2d(64, 32, 3, stride=1, padding=1),\n",
    "    torch.nn.ReLU(),\n",
    "    torch.nn.Conv2d(32, 16, 3, stride=1, padding=1),\n",
    "    torch.nn.ReLU(),\n",
    "    torch.nn.Conv2d(16, 8, 3, stride=1, padding=1),\n",
    "    torch.nn.ReLU(),\n",
    "    torch.nn.Conv2d(8, 3, 3, stride=1, padding=1),\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we have a cuda enabled graphics card, we can run our code a lot faster, but we need to tell the system to use it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.cuda()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have our neural network, we need to define our loss function and our optimizer. First, let's tell the system that we want to look at the Mean Square Error between our source image and our target image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "loss_fn = torch.nn.MSELoss()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, let's tell it what we are wanting to adjust to get a smaller Mean Square Error. In this case, we want to adjust all of the layers in our neural network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "params = model.parameters()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we will define an optimizer that we can call that will adjust those parameters by a tiny amount to get a smaller loss."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "learning_rate = 0.001\n",
    "optimizer = torch.optim.Adam(params, lr=learning_rate)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 3: Training the Network\n",
    "\n",
    "We now need to tell the system how many images to run at a time (batch size), how many times it should go through the training set (epochs) and how often it should print (skip)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "b = 8 # Number of images per round\n",
    "num_epochs = 800\n",
    "skip = 10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is good practice to shuffle your data as you train your network. This prevents the neural network from learning patterns between neighboring images. It turns out that pytorch has some sweet modules that will automatically take care of the shuffling and data management for us so that correct inputs stay with their correct outputs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Setup Dataloaders\n",
    "train_data = torch.utils.data.TensorDataset(torch.from_numpy(train_orig), torch.from_numpy(train_refc))\n",
    "train_loader = torch.utils.data.DataLoader(train_data, batch_size=b, shuffle=True)\n",
    "test_data = torch.utils.data.TensorDataset(torch.from_numpy(test_orig), torch.from_numpy(test_refc))\n",
    "test_loader = torch.utils.data.DataLoader(test_data, batch_size=b, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we setup our training loop. Here is the full loop."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#1. Outer for loop\n",
    "for epoch in range(num_epochs):\n",
    "\n",
    "    print(\"Epoch\", epoch)\n",
    "    i = 0\n",
    "    \n",
    "    # 2. Inner for loop\n",
    "    for batch_input, batch_output in train_loader:\n",
    "        \n",
    "        # 3. Make Pytorch friendly data\n",
    "        batch_input = Variable(batch_input,requires_grad=False).cuda()\n",
    "        batch_output = Variable(batch_output,requires_grad=False).cuda()\n",
    "\n",
    "        # 4. Forward Pass\n",
    "        result = model(batch_input)\n",
    "        loss = loss_fn(result, batch_output)\n",
    "        \n",
    "        # 5. Training step\n",
    "        optimizer.zero_grad() #Forget what you did last time\n",
    "        loss.backward() #Figure out what will make the loss smaller\n",
    "        optimizer.step() #Step that direction\n",
    "\n",
    "        # 6. Printing statement\n",
    "        i += 1\n",
    "        if i % skip == 0:\n",
    "            print(i,loss.data[0])\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's analyze this piece by piece.\n",
    "\n",
    "1. This is the outer for loop. This simply guarantees that you will go through the entire dataset at least num_epochs of times.\n",
    "2. This is the inner for loop. The data loader will automatically feed it a set of data to train on. That data will be shuffled and correctly organized to go through a single pass of the data.\n",
    "3. This make the data ready to feed into the nueral network. *requires_grad=False* means that you do not want the input to be changeable (you are not modifying the images). *.cuda()* is only used if you have a CUDA capable graphics card. Remove it if you don't.\n",
    "4. This runs the images through the neural network and then compares how close the result is to the actual image.\n",
    "5. This set of code adjusts the parameters accordingly to get better next time.\n",
    "6. This prints out your current loss so that you can keep track of progress."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 4: Analyzing Results\n",
    "\n",
    "Now that you have trained the network, the first thing you should do is save it in case something breaks. This way, you won't have to retrain the network to continue analyzing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "torch.save(model, \"trained_model.pt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now start feeding data from our testing set and seeing how it does. To start, let's just grab a single image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_input = test_orig[0:1]\n",
    "test_output = test_refc[0:1]\n",
    "test = Variable(torch.from_numpy(test_image), requires_grad=False).cuda()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can feed it through the network and compare the result."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "result = model(test)\n",
    "loss = loss_fn(result, test_output)\n",
    "print(\"test Loss\", loss.data[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we want to save the resulting image, we need to convert the pytorch variable back into numpy, transpose it back to a numpy image format and then save it using scipy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from scipy.misc import imsave\n",
    "result_image = original_image = np.transpose(result.data.cpu().numpy(),(0,2,3,1))\n",
    "imsave(\"result.png\", result_image[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that this is just an example. In good practice, you should find your test data loss at the end of each epoch. You would also want to go through the entire test data set instead of a single image. Just use the data loader to do this just like we did with the training data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
